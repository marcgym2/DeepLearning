{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0911396a-efbe-4ef4-a7a6-1393de06b7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023643a6-dd77-4a8d-bc7c-5add2fe4abeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6508 entries, 0 to 6507\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            6508 non-null   int64 \n",
      " 1   url           6508 non-null   object\n",
      " 2   title         6508 non-null   object\n",
      " 3   subtitle      3479 non-null   object\n",
      " 4   image         6361 non-null   object\n",
      " 5   claps         6508 non-null   int64 \n",
      " 6   responses     6508 non-null   object\n",
      " 7   reading_time  6508 non-null   int64 \n",
      " 8   publication   6508 non-null   object\n",
      " 9   date          6508 non-null   object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 508.6+ KB\n"
     ]
    }
   ],
   "source": [
    "medium_data = pd.read_csv('/Users/marcgrayson/Downloads/medium_data.csv')\n",
    "medium_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209ebdfe-1482-4e49-acc9-dcab6bad7689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 3-step guide to surviving guilt\n",
      "30 Days With No Social Media, or News. A Personal Experiment\n",
      "The Coming Cloud Gaming Wars\n",
      "Correlation does not imply causation\n",
      "How to be a Successful Entrepreneur, in Two Easy Steps\n",
      "Programmers health\n",
      "We Need to Talk About KFC’s Twitter Game\n",
      "The 5 Classification Evaluation metrics every Data Scientist must know\n",
      "Clustering Evaluation strategies\n",
      "Why do kids take their own lives?\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    rand_index = random.randint(0, len(medium_data) - 1)\n",
    "    rand_title = medium_data.iloc[rand_index, 2]\n",
    "    print(rand_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c19780f-35bf-470f-a913-a2114174b55b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'\\xa0',u' '))\n",
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace('\\u200a',' '))\n",
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'</strong>',u' '))\n",
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'<strong class=\"markup--strong markup--h3-strong\">',u' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06623b6d-0516-4f77-beec-4cb69ec7e220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se crea una instancia del Tokenizer con un token especial \"<oov>\" para palabras fuera del vocabulario\n",
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "\n",
    "# Se ajusta el tokenizador utilizando los datos de la columna 'title' del DataFrame medium_data\n",
    "tokenizer.fit_on_texts(medium_data['title'])\n",
    "\n",
    "# Se calcula el número total de palabras en el vocabulario, agregando 1 para el token \"<oov>\"\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f25830ae-b015-4127-98bb-b37229b920c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  8237\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of words: \", total_words-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d0c7b5-4f6a-4f43-bc7c-d355ce4742f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in medium_data['title']:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfb4db1-c216-4ce7-a8cb-ece899c6c700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input sequences:  45749\n"
     ]
    }
   ],
   "source": [
    "print(\"Total input sequences: \", len(input_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9915c5-525a-4149-8316-db83d436558d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 675, 64, 2, 451, 1518, 12]\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a658933-23d6-4283-81b8-42dd0a832799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An Easy Introduction to SQL for Data Scientists'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data.iloc[5,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4706a999-b97c-4e6d-8fce-b168b7fc4d59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          4,  675,   64,    2,  451, 1518,   12], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrar la longitud máxima de las secuencias de entrada existentes\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "# Hacer que todas las secuencias de entrada tengan la misma longitud usando el relleno (padding)\n",
    "# Se utiliza 'pre' para rellenar al inicio de cada secuencia\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Acceder a la segunda secuencia de entrada después del relleno\n",
    "input_sequences[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5480cdd-449d-4a69-9631-bc84b48f6dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create features and label\n",
    "x, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d5cf52-b69f-47e4-90ca-3882b9fc7096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 17:58:36.714810: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 52s 35ms/step - loss: 7.2637 - accuracy: 0.0542\n",
      "Epoch 2/10\n",
      "1430/1430 [==============================] - 50s 35ms/step - loss: 6.5137 - accuracy: 0.0917\n",
      "Epoch 3/10\n",
      "1430/1430 [==============================] - 51s 36ms/step - loss: 5.9793 - accuracy: 0.1256\n",
      "Epoch 4/10\n",
      "1430/1430 [==============================] - 50s 35ms/step - loss: 5.4952 - accuracy: 0.1514\n",
      "Epoch 5/10\n",
      "1430/1430 [==============================] - 50s 35ms/step - loss: 5.0256 - accuracy: 0.1754\n",
      "Epoch 6/10\n",
      "1430/1430 [==============================] - 50s 35ms/step - loss: 4.5787 - accuracy: 0.2051\n",
      "Epoch 7/10\n",
      "1430/1430 [==============================] - 54s 38ms/step - loss: 4.1634 - accuracy: 0.2456\n",
      "Epoch 8/10\n",
      "1430/1430 [==============================] - 52s 36ms/step - loss: 3.7686 - accuracy: 0.2980\n",
      "Epoch 9/10\n",
      "1430/1430 [==============================] - 51s 36ms/step - loss: 3.4030 - accuracy: 0.3512\n",
      "Epoch 10/10\n",
      "1430/1430 [==============================] - 50s 35ms/step - loss: 3.0712 - accuracy: 0.4063\n",
      "<keras.engine.sequential.Sequential object at 0x1669a55d0>\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(x, y, epochs=10, verbose=1)\n",
    "#print model.summary() \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0c45285-c444-45ac-91c7-799b1b193133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Easy Introduction to SQL for data scientists\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"An Easy Introduction to SQL\"\n",
    "next_words = 3\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    predicted = np.argmax(predicted_probs, axis=-1)  # toma la clase con la probabilidad más alta\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29dbeab8-c295-4137-9dd9-919676eb2ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1430/1430 [==============================] - 30s 21ms/step - loss: 7.3430\n",
      "Epoch 2/10\n",
      "1430/1430 [==============================] - 31s 22ms/step - loss: 6.7378\n",
      "Epoch 3/10\n",
      "1430/1430 [==============================] - 30s 21ms/step - loss: 6.2850\n",
      "Epoch 4/10\n",
      "1430/1430 [==============================] - 30s 21ms/step - loss: 5.8886\n",
      "Epoch 5/10\n",
      "1430/1430 [==============================] - 30s 21ms/step - loss: 5.5174\n",
      "Epoch 6/10\n",
      "1430/1430 [==============================] - 30s 21ms/step - loss: 5.1651\n",
      "Epoch 7/10\n",
      "1430/1430 [==============================] - 30s 21ms/step - loss: 4.8320\n",
      "Epoch 8/10\n",
      "1430/1430 [==============================] - 29s 21ms/step - loss: 4.5123\n",
      "Epoch 9/10\n",
      "1430/1430 [==============================] - 30s 21ms/step - loss: 4.2057\n",
      "Epoch 10/10\n",
      "1430/1430 [==============================] - 30s 21ms/step - loss: 3.9094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16d3e3040>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model3.add(LSTM(100))  # Usamos 20 unidades en la capa LSTM\n",
    "model3.add(Dense(total_words, activation='softmax'))  # Usamos tantas neuronas como palabras en el vocabulario y activación softmax\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model3.fit(x, y, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e98b31a0-9057-44ee-b38c-f6617c53753c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1430/1430 [==============================] - 13s 9ms/step - loss: 1201082.2500\n",
      "Epoch 2/10\n",
      "1430/1430 [==============================] - 12s 9ms/step - loss: 274872.5000\n",
      "Epoch 3/10\n",
      "1430/1430 [==============================] - 13s 9ms/step - loss: 197111.5469\n",
      "Epoch 4/10\n",
      "1430/1430 [==============================] - 12s 9ms/step - loss: 158638.2344\n",
      "Epoch 5/10\n",
      "1430/1430 [==============================] - 12s 9ms/step - loss: 120151.7031\n",
      "Epoch 6/10\n",
      "1430/1430 [==============================] - 12s 8ms/step - loss: 90930.0078\n",
      "Epoch 7/10\n",
      "1430/1430 [==============================] - 12s 9ms/step - loss: 73917.7734\n",
      "Epoch 8/10\n",
      "1430/1430 [==============================] - 13s 9ms/step - loss: 66569.0547\n",
      "Epoch 9/10\n",
      "1430/1430 [==============================] - 12s 9ms/step - loss: 63404.8086\n",
      "Epoch 10/10\n",
      "1430/1430 [==============================] - 12s 9ms/step - loss: 74548.3672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16dbf9d20>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model4.add(LSTM(20))  # Corrección aquí\n",
    "model4.add(Dense(1)) \n",
    "model4.compile(loss='mape', optimizer='adam')\n",
    "model4.fit(x, y, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "308fba74-28fc-4554-99be-8ebd20fbc54e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1430/1430 [==============================] - 49s 34ms/step - loss: 2.7699 - accuracy: 0.4589\n",
      "Epoch 2/10\n",
      "1430/1430 [==============================] - 50s 35ms/step - loss: 2.5003 - accuracy: 0.5076\n",
      "Epoch 3/10\n",
      "1430/1430 [==============================] - 48s 33ms/step - loss: 2.2630 - accuracy: 0.5502\n",
      "Epoch 4/10\n",
      "1430/1430 [==============================] - 48s 34ms/step - loss: 2.0509 - accuracy: 0.5907\n",
      "Epoch 5/10\n",
      "1430/1430 [==============================] - 49s 34ms/step - loss: 1.8621 - accuracy: 0.6262\n",
      "Epoch 6/10\n",
      "1430/1430 [==============================] - 49s 34ms/step - loss: 1.6924 - accuracy: 0.6629\n",
      "Epoch 7/10\n",
      "1430/1430 [==============================] - 49s 34ms/step - loss: 1.5446 - accuracy: 0.6895\n",
      "Epoch 8/10\n",
      "1430/1430 [==============================] - 49s 34ms/step - loss: 1.4158 - accuracy: 0.7153\n",
      "Epoch 9/10\n",
      "1430/1430 [==============================] - 49s 34ms/step - loss: 1.3017 - accuracy: 0.7391\n",
      "Epoch 10/10\n",
      "1430/1430 [==============================] - 49s 34ms/step - loss: 1.2034 - accuracy: 0.7575\n",
      "<keras.engine.sequential.Sequential object at 0x16dbfac50>\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model5.add(Bidirectional(LSTM(150)))\n",
    "model5.add(Dense(total_words, activation='softmax'))\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(x, y, epochs=10, verbose=1)\n",
    "#print model.summary() \n",
    "print(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c9e6d56-7b47-4238-9919-aa31f712bf28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Easy Introduction to SQL unlimited jerry unlimited\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"An Easy Introduction to SQL\"\n",
    "next_words = 3\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model5.predict(token_list, verbose=0)\n",
    "    predicted = np.argmax(predicted_probs, axis=-1)  # toma la clase con la probabilidad más alta\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a9b2b-37cf-492b-bdad-5539e259a567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
